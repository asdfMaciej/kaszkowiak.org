---
title: "Embeddingi w piguÅ‚ce"
date: 2023-12-21T08:00:00+02:00
lastmod: 2026-01-19T08:00:00+02:00
summary: "Czym sÄ… embeddingi, z ktÃ³rych prawdopodobnie korzystasz na codzieÅ„? Dowiedz siÄ™ w artykule - wiele buzzwordÃ³w przestanie byÄ‡ czarnÄ… magiÄ… ğŸ§™"
thumbnail: "embeddings.png"
tags: ["ulepsz swoje AI", "ai", "ml", "nlp", "python", "rag"]
---

Przyjmijmy, Å¼e chcemy, aby nasz komputer przetworzyÅ‚ jakiÅ› tekst.

Zastosowanie moÅ¼e byÄ‡ dowolne: 

- prosimy ChatGPT o korektÄ™ naszej wiadomoÅ›ci, 
- prÃ³bujemy przetÅ‚umaczyÄ‡ wiadomoÅ›Ä‡,
- lub np. wykorzystujemy algorytm do rozpoznania emocji w tekÅ›cie.

We wszystkich podejÅ›ciach pojawia siÄ™ jeden problem.

**Jak komputer, myÅ›lÄ…cy liczbami, bajtami i bitami, moÅ¼e przetworzyÄ‡ tekst zÅ‚oÅ¼ony z ludzkiej mowy, czyli sÅ‚Ã³w i liter?**

OtÃ³Å¼, przed rozpoczÄ™ciem przetwarzania, komputer tÅ‚umaczy tekst na swÃ³j jÄ™zyk. 
Zamienia sÅ‚owa i zdania na zbiÃ³r liczb o okreÅ›lonej strukturze, zwany embeddingami :)

## Czym sÄ… embeddingi?

Embeddingi to reprezentacja tekstu [1] w postaci N-wymiarowego wektora. 
Tekstem moÅ¼e byÄ‡ sÅ‚owo, zdanie, kilka zdaÅ„, czy teÅ¼ kilka paragrafÃ³w.

PrzykÅ‚adowo, wyraz "Kot" moÅ¼e zostaÄ‡ zamieniony w wektor `[0.123, 0.892, 0.004, ..., 0.572]` ktÃ³ry zawiera 300 liczb z wartoÅ›ciÄ… pomiÄ™dzy -1 a 1.

Zdanie "Bardzo lubiÄ™ jeÅ›Ä‡ czekoladÄ™ w adwent" rÃ³wnieÅ¼ zostanie zamienione w wektor o identycznej strukturze - otrzymamy 300 liczb z wartoÅ›ciÄ… pomiÄ™dzy -1 a 1. 

Same wartoÅ›ci wektorÃ³w sÄ… nieczytelne dla nas, jako ludzi. PrzykÅ‚adowo, nie jesteÅ›my w stanie odczytaÄ‡ Å¼adnych informacji z tego, Å¼e otrzymaliÅ›my -1 na 54tej pozycji wektora, lub 0,5 na 13tej pozycji. 

{{< notice-feather-icons info >}}
[1] Embeddingi mogÄ… byÄ‡ rÃ³wnieÅ¼ generowane dla zdjÄ™Ä‡, filmÃ³w czy audio. Sam koncept embeddingÃ³w odnosi siÄ™ do zamiany skomplikowanych danych (jak tekst czy zdjÄ™cie) w wektor liczb. 

Aby artykuÅ‚ pozostaÅ‚ prosty, omÃ³wiÄ™ wyÅ‚Ä…cznie ich znaczenie tekstowe, bo jest aktualnie najczÄ™Å›ciej wykorzystywane :)  
{{</ notice-feather-icons >}}

### Co nam dajÄ… embeddingi?

PorÃ³wnywanie dwÃ³ch wektorÃ³w pozwala nam okreÅ›liÄ‡, jak bardzo odpowiadajÄ…ce im sÅ‚owa / zdania sÄ… semantycznie podobne. 

Nie chodzi jednak o samÄ… konstrukcjÄ™ sÅ‚owa - czy "prÄ…d" jest podobny do "prad", "prda", czy "prdÄ…" - jak w tradycyjnym wyszukiwaniu opartym o sÅ‚owa kluczowe.

PodobieÅ„stwo semantyczne jest ustalane po ludzku - czy sÅ‚owa / zdania majÄ… podobne znaczenie.

## PorÃ³wnywanie sÅ‚Ã³w - o historii embeddingÃ³w

### word2vec

PrzedstawiÄ™ przykÅ‚ad w oparciu o pionerski algorytm word2vec, opublikowany w 2013 przez TomÃ¡Å¡a Mikolova z Google.

Algorytm word2vec powstaÅ‚ poprzez przetworzenie bardzo duÅ¼ego korpusu tekstu. UmoÅ¼liwiÅ‚o to samoistne znalezienie podobieÅ„stw, bez koniecznoÅ›ci nadzoru i dodatkowej pracy ze strony badaczy (unsupervised learning).

{{< img src="train.png" alt="word2vec, podobne sÅ‚owa do train, ÅºrÃ³dÅ‚o: vectors.nlpl.eu" >}}

SÅ‚owo "train" zostaje okreÅ›lone jako podobne do "intercity", "tram", "trainset", "freight", "railcar", "passenger", "bus": 

- "train" - "tram"/"bus", bo komunikacja publiczna;
- "train" - "freight", bo kolej towarowa;
- "train" - "passenger", bo kolej pasaÅ¼erska;
...

Pomimo sÅ‚Ã³w o zupeÅ‚nie odmiennej konstrukcji, algorytm trafnie oddaÅ‚ ich znaczenie przez ustalenie podobieÅ„stw.

**WyobraÅºcie sobie, jak bardzo uÅ‚atwia to wyszukiwanie w Internecie!** Aby znaleÅºÄ‡ wyniki zwiÄ…zane z "transport miejski", "miejskie przedsiÄ™biorstwo komunikacyjne" i "rozkÅ‚ad jazdy", wystarczy, Å¼e wpiszemy "komunikacja publiczna". Nie bez powodu wiodÄ…cy research (zarÃ³wno dla word2vec, jak i poÅºniej omawianego BERT) byÅ‚ prowadzony przez Google.

Mechanizm porÃ³wywnywania embeddingÃ³w to prosta operacja matematyczna. Mierzymy odlegÅ‚oÅ›Ä‡ pomiÄ™dzy dwoma punktami - tylko zamiast dwÃ³ch lub trzech wymiarÃ³w, jak to miaÅ‚o miejsce na matematyce, operujemy na N wymiarach, gdzie N jest rozmiarem wektora. 

Kluczowy wniosek - porÃ³wnywanie istniejÄ…cych embeddingÃ³w jest znacznie szybsze od generowania nowych.

Co wiÄ™cej, wektorami w word2vec moÅ¼na manipulowaÄ‡:

JeÅ›li do jednego wektora dodamy drugi wektor, a nastÄ™pnie odejmiemy trzeci wektor, to moÅ¼e siÄ™ okazaÄ‡, Å¼e wynik jest bardzo zbliÅ¼ony do istniejÄ…cego sÅ‚owa! [\[3\]](https://www.theaidream.com/post/word-embeddings-in-natural-language-processing-nlp)

- Wynik "man" + "queen" - "woman" jest najbardziej zbliÅ¼ony do "king"
- Wynik "Rome" + "France" - "Paris" jest najbardziej zbliÅ¼ony do "Italy"
- Wynik "Man" + "Sister" - "Woman" jest najbardziej zbliÅ¼ony do "Brother"

Niesamowite, prawda? :)

## PorÃ³wnywanie zdaÅ„

PowyÅ¼sze przykÅ‚ady przedstawiÅ‚em dla pojedynczych sÅ‚Ã³w, ale algorytm dziaÅ‚a rÃ³wnie dobrze dla zdaÅ„, czy takÅ¼e zbiorÃ³w zdaÅ„.

Przyjmijmy, Å¼e mamy bazÄ™ wiedzy, w postaci 3 nastÄ™pujÄ…cych zdaÅ„:

- ZbliÅ¼ajÄ… siÄ™ Å›wiÄ™ta!
- MasÅ‚o orzechowe jest dobrym ÅºrÃ³dÅ‚em biaÅ‚ka.
- Maciej ma na sobie czerwony Å›wiÄ…teczny sweter...

Mamy rÃ³wnieÅ¼ pytanie, dla ktÃ³rego chcemy znaleÅºÄ‡ najbardziej podobne zdanie:

- Jak polepszyÄ‡ dietÄ™?

Gdy: 

- wygenerujemy embeddingi dla wszystkich 4 zdaÅ„
- oraz porÃ³wnamy wszystkie 3 pary (embedding pytania) - (embedding zdania)

Dla kaÅ¼dej pary otrzymamy liczbowÄ… wartoÅ›Ä‡ podobieÅ„stwa - im wyÅ¼sza, tym bardziej zbliÅ¼one sÄ… zdania.

Najbardziej trafnym dopasowaniem do pytania "**Jak polepszyÄ‡ dietÄ™?**" prawdopodobnie okaÅ¼e siÄ™ zdanie "**MasÅ‚o orzechowe jest dobrym ÅºrÃ³dÅ‚em biaÅ‚ka.**" - pomimo tego, Å¼e nie pokrywajÄ… siÄ™ Å¼adne sÅ‚owa kluczowe!  

Ta technika jest wykorzystywana chociaÅ¼by w [Retrieval Augmented Generation](/blog/retrieval-augmented-generation/), ktÃ³re umoÅ¼liwia nam znalezienie najbardziej dopasowanych dokumentÃ³w do pytania uÅ¼ytkownika, a nastÄ™pnie udzielenie na ich podstawie odpowiedzi przez LLM (jak np. ChatGPT). JeÅ›li nie znasz tej metody: zachÄ™cam do zapoznania siÄ™ z [artykuÅ‚em o RAG!](/blog/retrieval-augmented-generation/)

{{< gallerystart >}}
{{< img src="rag.png" alt="Å¹rÃ³dÅ‚o: blog.langchain.dev" >}}
{{< galleryend >}}


### Nowsze algorytmy 

GÅ‚Ã³wnym problemem word2vec jest sÅ‚abe rozpoznawanie kontekstu dla wyrazÃ³w. PrzykÅ‚adowo, w zdaniach:

- apple and banana republic are american brands
- apple and banana are popular fruits

Ten sam embedding zostanie wygenerowany dla sÅ‚Ã³w "apple" i "banana", pomimo Å¼e w pierwszym zdaniu odnoszÄ… siÄ™ do firm, a w drugim do owocÃ³w. [\[12\]](https://datascience.stackexchange.com/questions/54232/bert-vs-word2vec-is-bert-disambiguating-the-meaning-of-the-word-vector)

word2vec zostaÅ‚o szybko zastÄ…pione przez nowsze modele, generujÄ…ce embeddingi o lepszej jakoÅ›ci.

**Kluczowe jest, aby porÃ³wnywaÄ‡ ze sobÄ… embeddingi uzyskane wyÅ‚Ä…cznie tÄ… samÄ… metodÄ….** Zestawienie ze sobÄ… embeddingÃ³w wygenerowanych przez dwa rÃ³Å¼ne modele, nie da nam Å¼adnego wymiernego rezultatu.

### BERT

W 2018 roku naukowcy z Google przedstawili model BERT, oparty o architekturÄ™ transformerÃ³w. [\[5\]](https://en.wikipedia.org/wiki/BERT_(language_model))

W odrÃ³Å¼nieniu od word2vec, w BERT embeddingi sÅ‚Ã³w sÄ… zaleÅ¼ne od kontekstu. Co wiÄ™cej, BERT umoÅ¼liwiÅ‚ embeddowanie caÅ‚ych zdaÅ„! Dla poniÅ¼szych zdaÅ„:

- apple and banana republic are american brands
- apple and banana are popular fruits

Odmienne znaczenie tych samych sÅ‚Ã³w "apple" oraz "banana" nie wpÅ‚ynie juÅ¼ negatywnie na jakoÅ›Ä‡ embeddingÃ³w.

Natomiast ze wzglÄ™du na innÄ… architekturÄ™, BERT uniemoÅ¼liwia operowanie na embeddingach, jak w powyÅ¼szych przykÅ‚adach - czy to przez wizualizacje sÄ…siadÃ³w, czy przez matematykÄ™ na wektorach. [\[12\]](https://datascience.stackexchange.com/questions/54232/bert-vs-word2vec-is-bert-disambiguating-the-meaning-of-the-word-vector) Na szczÄ™Å›cie to zupeÅ‚nie nie jest potrzebne w praktyce :)

### SBERT

BERT zadziaÅ‚aÅ‚o doskonale dla pojedynczych sÅ‚Ã³w, ale embeddingi caÅ‚ych zdaÅ„ nie byÅ‚y jeszcze doszlifowane.   

W 2019 roku powstaÅ‚ model SBERT, ulepszajÄ…cy model BERT i uÅ‚atwiajÄ…cy porÃ³wnywanie poszczegÃ³lnych zdaÅ„. [\[6\]](https://www.sbert.net/)

SBERT dla kaÅ¼dego zdania generuje nam wektor, czyli embedding, na ktÃ³rym moÅ¼emy operowaÄ‡ poza sieciÄ… neuronowÄ…. Przyspieszenie procesu wzglÄ™dem BERT przy zachowaniu jakoÅ›ci okazaÅ‚o siÄ™ gigantyczne, poniewaÅ¼ Ã³wczesne rozwiÄ…zania SoTA wymagaÅ‚y kalkulowania podobieÅ„stwa poprzez inferencjÄ™ sieci BERT. SBERT umoÅ¼liwiÅ‚ wykonywanie prostego podobieÅ„stwa cosinusowego na wygenerowanych wektorach. ZacytujÄ™ tutaj oryginalny paper:

{{< quote source="Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks" src="https://arxiv.org/abs/1908.10084">}}
BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations (\~65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering.  

In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. **This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT**.   
{{< /quote >}}


## ZwiÄ™kszanie trafnoÅ›ci porÃ³wnywania zdaÅ„

WrÃ³cÄ™ jeszcze do samego porÃ³wnywania zdaÅ„ pod kÄ…tem podobieÅ„stwa. To aktualnie prawdopodobnie najczÄ™ste zastosowanie embeddingÃ³w.

### Bi-encoder

NajprostszÄ… metodÄ… jest porÃ³wnywanie odpowiadajÄ…cym im embeddingÃ³w za pomocÄ… cosine similiarity. Jest to tak zwany **bi-encoder**. To dokÅ‚adnie ten sam mechanizm, co opisaÅ‚em dla przykÅ‚adu SBERT :) Jest to rÃ³wnieÅ¼ aktualnie najczÄ™Å›ciej stosowana metoda w aplikacjach GenAI - z API otrzymujemy embeddingi, ktÃ³re zapisujemy w bazie, a nastÄ™pnie wykonujemy na nich operacje.

Metoda jest skuteczna i szybka, jednak nie jest stricte najlepsza pod kÄ…tem jakoÅ›ci. 

### Cross-encoder 

Znacznie lepszÄ… jakoÅ›Ä‡ oferuje nam cross encoder: [\[13\]](https://www.sbert.net/examples/applications/cross-encoder/README.html) 

- Bi-encoder zwraca dla jednego fragmentu wektor, ktÃ³ry nastÄ™pnie moÅ¼emy porÃ³wnaÄ‡ z dowolnym innym wektorem.
- Cross-encoder zwraca dla dwÃ³ch fragmentÃ³w wartoÅ›Ä‡ pomiÄ™dzy 0 a 1 wskazujÄ…cÄ… na to, jak zbliÅ¼one sÄ… dwa wyrazy, zdania, czy teÅ¼ dokumenty.

{{< img src="bi vs cross.png" alt="Bi-encoder vs cross-encoder, ÅºrÃ³dÅ‚o: sbert.net">}}

Problemem jest jednak prÄ™dkoÅ›Ä‡. Nie jesteÅ›my w stanie w rozsÄ…dnym czasie uruchomiÄ‡ modelu na kaÅ¼dej parze zdaÅ„ (co wskazuje rÃ³wnieÅ¼ cytat z paperu SBERT). 

Jak wiÄ™c wykorzystaÄ‡ cross-encoder do polepszenia jakoÅ›ci?

### Re-ranking

Na ratunek przychodzi re-ranking: to technika, ktÃ³ra umoÅ¼liwia nam wykorzystanie cross-encodera do wybrania najlepszego fragmentu spoÅ›rÃ³d zbioru kandydatÃ³w wybranych przez bi-encodera. [\[14\]](https://www.sbert.net/examples/applications/retrieve_rerank/README.html) 

- W pierwszej kolejnoÅ›ci szukamy dla naszego pytania duÅ¼y zbiÃ³r (np 100) najtrafniejszych tekstÃ³w;
- NastÄ™pnie wykorzystujemy Cross Encoder, aby zbadaÄ‡ podobieÅ„stwo pomiÄ™dzy pytaniem, a otrzymanymi tekstami.

ZnaczÄ…co zwiÄ™ksza to trafnoÅ›Ä‡ wyszukiwania przy stosunkowo niewielkim wzroÅ›cie czasu oczekiwania za odpowiedziÄ…. Wzrost jakoÅ›ci jest bardzo odczuwalny przy duÅ¼ych zbiorach tekstÃ³w. 

MoÅ¼na potraktowaÄ‡ to jako wstÄ™pny przesiew kandydatÃ³w (wysoki recall), z ktÃ³rego wyÅ‚aniamy najlepsze dopasowania (zwiÄ™kszamy accuracy).

DemonstrujÄ…c na przykÅ‚adzie opartym o dane z Wikipedii, bi-encoder â€˜multi-qa-MiniLM-L6-cos-v1â€˜, cross-encoder â€˜cross-encoder/ms-marco-MiniLM-L-6-v2â€˜ oraz wyszukiwanie leksykalne BM25: [\[15\]](https://github.com/UKPLab/sentence-transformers/blob/master/examples/applications/retrieve_rerank/retrieve_rerank_simple_wikipedia.ipynb) 

{{< gallerystart >}}
{{< img src="bm25.png" alt="Wynik - BM25 (wstÄ™pne przeszukanie)">}}
{{< img src="biencoder.png" alt="Wynik - bi-encoder (wstÄ™pne przeszukanie)">}}
{{< galleryend >}}

Odpowiedzi otrzymane po re-rankingu sÄ… znacznie lepsze od odpowiedzi znalezionych przez BM25 i sam bi-encoder:

{{< img src="reranking.png" alt="Wynik - po re-rankingu">}}

Fragmenty po re-rankingu nawiÄ…zujÄ… bezpoÅ›rednio do naszego pytania - technika dziaÅ‚a :)

## ZwiÄ™kszanie szybkoÅ›ci porÃ³wnywania

Wyszukiwanie trafnych embeddingÃ³w staje siÄ™ czasochÅ‚onne przy duÅ¼ych zbiorach danych.

Najprostszy sposÃ³b, czyli iterowanie po kolejnych wektorach, ma zÅ‚oÅ¼onoÅ›Ä‡ czasowÄ… liniowÄ… wzglÄ™dem rozmiaru naszej bazy embeddingÃ³w. 

10 milionÃ³w embeddingÃ³w wymaga porÃ³wnania 10 milionÃ³w wektorÃ³w z wektorem otrzymanym dla naszego pytania.

Z tego powodu powstaÅ‚y bazy wektorowe, ktÃ³re przyÅ›pieszajÄ… proces wyszukiwania. [\[16\]](https://www.pinecone.io/learn/vector-database/) 

**NaleÅ¼y wspomnieÄ‡, Å¼e przyÅ›pieszanie wyszukiwania jest procesem stratnym. Nie jesteÅ›my w stanie utrzymaÄ‡ perfekcyjnej jakoÅ›ci wyszukiwaÅ„, jednoczeÅ›nie redukujÄ…c prÄ™dkoÅ›Ä‡.** CzÄ™sto jest to jednak akceptowalny trade-off w produkcyjnych systemach.

Efektywne przechowywanie wektorÃ³w jest moÅ¼liwe nawet w Postgresie z wykorzystaniem pgvector. [\[17\]](https://cloud.google.com/blog/products/databases/faster-similarity-search-performance-with-pgvector-indexes) 

## PrzykÅ‚ad w Pythonie

SBERT jest dostÄ™pny pod PythonowÄ… bibliotekÄ… [SentenceTransformers](https://www.sbert.net/). Wykorzystanie wymaga zaledwie kilku linijek kodu:

```python
from sentence_transformers import SentenceTransformer, util
model = SentenceTransformer('all-MiniLM-L6-v2')

emb1 = model.encode("This is a red cat with a hat.")
emb2 = model.encode("Have you seen my red cat?")

cos_sim = util.cos_sim(emb1, emb2)
print("PodobieÅ„stwo: ", cos_sim)
```

Embeddingi moÅ¼emy generowaÄ‡ wykorzystujÄ…c wyÅ‚Ä…cznie procesor. Posiadanie karty graficznej przyspieszy ten proces, jednak nie jest wymagane do inferencji (odpytywania) modelu.  

## Jaki model wykorzystaÄ‡ do wygenerowania embeddingÃ³w?

Model moÅ¼emy wybraÄ‡ w oparciu o [MTEB leaderboard](https://huggingface.co/spaces/mteb/leaderboard), ktÃ³ry przedstawia jakoÅ›Ä‡ poszczegÃ³lnych modeli dla rÃ³Å¼nych zadaÅ„ i jÄ™zykÃ³w - w tym jÄ™zyka polskiego! MTEB to akronim od Massive Text Embedding Benchmark.

Ranking moÅ¼emy przefiltrowaÄ‡ po zadaniach takich jak np. klasyfikacja, reranking czy retrieval.

{{< img src="mteb.png" alt="MTEB Leaderboard" >}}

OperujÄ…c na przykÅ‚adzie wyszukiwania najbardziej zbliÅ¼onego zdania do pytania, aby znaleÅºÄ‡ odpowiedni model, powinniÅ›my wybraÄ‡ zakÅ‚adkÄ™ "Retrieval" oraz jÄ™zyk polski. 

### Specjalistyczne zastosowania

Jako ciekawostkÄ™: moÅ¼emy dotrenowaÄ‡ model embeddingÃ³w na wÅ‚asnym korpusie tekstu. Takie rozwiÄ…zanie usprawnia wyniki, poniewaÅ¼ model ma szansÄ™ nauczyÄ‡ siÄ™ specjalistycznego sÅ‚ownictwa w odpowiednim kontekÅ›cie.

Firma odpowiedzialna za Kelvin Legal wytrenowaÅ‚a swÃ³j model na korpusie dokumentÃ³w prawniczych oraz finansowych, znaczÄ…co przewyÅ¼szajÄ…c trafnoÅ›Ä‡ pozostaÅ‚ych modeli dla zwiÄ…zanych z nimi pytaniami. Ich najmniejszy model radzi sobie lepiej z dokumentami prawniczymi od najwiÄ™kszego modelu z OpenAI! [\[11\]](https://docs.kelvin.legal/docs/examples/due-dilligence/#retrieval-augmented-techniques-for-diligence-checklists--with-kelvin-vector-and-kelvin-embeddings) 

To wszystko na dzisiaj. DziÄ™ki za przeczytanie artykuÅ‚u! :)