---
title: "BM25: wyszukiwanie po sowach kluczowych"
date: 2024-09-24T00:00:00+02:00
lastmod: 2024-09-24T00:00:00+02:00
summary: "Jak dobrze wdro偶y BM25 w jzyku polskim? - poznaj problemy, rozwizania i realne przykady "
thumbnail: "placeholder.jpg"
draft: true
tags: ["ulepsz swoje AI", "ai", "python", "nlp", "rag", "retrieval"]
hidethumbnail: 1
---

# Co to BM25?

BM25 to funkcja, kt贸ra punktuje dopasowanie dokument贸w do zapytania u偶ytkownika. Jeli sowa w zapytaniu znajduj si w dokumencie, to dokument otrzyma punkty. 

BM25 jest domylnym algorytmem ElasticSearch ([src](https://www.elastic.co/blog/practical-bm25-part-2-the-bm25-algorithm-and-its-variables)) - to chyba najlepszy dow贸d, 偶e algorytm jest praktyczny :)

## Wykorzystanie

BM25 przyda si wszdzie tam, gdzie potrzebujemy wyszukiwanie po sowach kluczowych. 

Przykadowo: jest szeroko wykorzystywane w [aplikacjach RAG](/blog/retrieval-augmented-generation) jako element wyszukiwania hybrydowego. 

{{< notice-feather-icons info >}}
Wyszukiwanie hybrydowe to poczenie wyszukiwania semantycznego, [opartego na embeddingach](#todo), oraz wyszukiwania po sowach kluczowych, jak np. BM25. To czy zalety obu rozwiza:

- wyszukiwanie semantyczne jest w stanie znale藕 synonimy, zdania o podobnym znaczeniu, czy nawet w innym jzyku;
- wyszukiwanie po sowach kluczowych potrafi znale藕 zdania z niecodziennymi sowami, akronimami czy odwoujce si do niespotykanych wczeniej fraz. 

Poczenie np. 3 najlepszych wynik贸w z wyszukiwania semantycznego i 3 najlepszych z BM25, pozwala nam przewa偶nie osign znacznie lepsze wyniki ni偶 6 wynik贸w z pojedynczej metody.
{{</ notice-feather-icons >}}

Zrozumienie mechanizmu dziaania oraz sztuczek zwizanych z implementacj staje si niezwykle przydatne - w szczeg贸lnoci dla jzyka polskiego!

### Jak dziaa BM25?

Algorytm analizuje czsto wystpowania poszczeg贸lnych s贸w kluczowych w zbiorze dokument贸w.   

Dokadny wz贸r i bardziej formalny opis [znajduje si na Wikipedii](https://en.wikipedia.org/wiki/Okapi_BM25) - jednak wa偶niejsze jest zrozumienie mechanizmu:

### Najwa偶niejsze zasady dziaania

Dokumenty oraz zapytania w pierwszej kolejnoci dzielone s na termy - przyjmijmy, 偶e po prostu na sowa.

Im rzadziej dopasowane sowa wystpuj w dokumentach, tym bardziej bd punktowane: 
- Jeli np. przeszukujemy zasoby ksigarni, to dla zapytania "ksi偶ka eklektyzm", dopasowania do rzadziej wystpujcego sowo "eklektyzm" bd bardziej punktowane ni偶 do sowa "ksi偶ka".
- Pospolite sowa bd znacznie mniej punktowane: np. w zdaniu "*co na* **obiad**", dopasowanie do "*co* wrzuci *na* grilla" bdzie znacznie sabsze ni偶 "pomysy na **obiad**" 

Im sowo czciej bdzie wystpowao w dokumencie, tym dokument otrzyma wiksz liczb punkt贸w. Dziki temu, dla zapytania "kot" bdzie bardziej punktowany artyku o kotach, ni偶 encyklopedia wymieniajaca wszystkie zwierzta. 

Algorytm uwzgldnia dugo dokument贸w, wic 1-stronicowy dokument z 1 dopasowaniem mo偶e otrzyma wiksz liczb punkt贸w ni偶 100-stronicowy dokument z 3 dopasowaniami. Liczy si gsto dopasowa w tekcie.  

BM25 ignoruje r贸wnie偶 wzgldn pozycj s贸w w dokumencie - zdanie "**czerwony** notatnik, czarny **so**" bdzie miao identyczne dopasowanie do zdania "**czerwony so** by zy", co zdanie "gdzie jest **czerwony so**?". Ka偶de sowo jest rozpatrywane indywidualnie.

## Pre-processing

BM25 dla skutecznego dziaania wymaga pre-processingu danych wejciowych. Przedstawi na przykadach istotne kroki:

#### Lowercasing 

BM25 przy domylnej tokenizacji (dzielimy zdania na sowa i tyle) bdzie rozr贸偶nia pomidzy du偶ymi a maymi znakami.  **Token "Czerwony" nie bdzie powizany z tokenem "czerwony".** 

Czy to jest po偶dane? W wikszoci przypadk贸w nie, wic **zamiana zdania na mae znaki (*lowercasing*) wyeliminuje ten problem**. Jednak jeli Wasza aplikacja np. operuje na kodach seryjnych, kt贸re rozr贸偶niaj mae i du偶e znaki, i chcielibycie umo偶liwi ich precyzyjne wyszukiwanie, to wprowadzenie takiego kroku mogoby pogorszy Wasze wyniki! 

Std zawsze warto si zastanowi: czy chcemy wprowadzi pre-processing?     

```python
# Przed zmianami
documents = ["Soce jest zielone"]
query = "Jakiego koloru jest soce"
search_bm25(documents, query) == []

# Po zmianach
documents = ["soce jest zielone"]
query = "jakiego koloru jest soce"
search_bm25(documents, query) == ["soce jest zielone"] # match na sowie soce
```

{{< notice-feather-icons note >}}
Zauwa偶cie, 偶e dane wejciowe musz by przetworzone w identyczny spos贸b, co dane dokument贸w w indeksie. Jeli np. chcemy usun polskie znaki - to musimy to robi zar贸wno dla zapytania u偶ytkownika, jak i dokument贸w. To tyczy si ka偶dego kroku.
{{</ notice-feather-icons >}}

### Usuwanie stopword贸w

{{< notice-feather-icons info >}}
Stopwordy to sowa powszechnie wystpujce w danym jzyku, na przykad: "to", "w", "jak", "z", "na".
{{</ notice-feather-icons >}}

Usuwanie stopword贸w sprawia, 偶e najczciej wystpujce sowa w danym jzyku zostan usunite: 

```python
remove_stopwords("jaka jest pogoda dzisiaj?") == "pogoda dzisiaj?"
remove_stopwords("pies jest bardzo szczliwy") == "pies szczliwy"
```

 Po usuniciu stopword贸w, "jaka **jest** pogoda dzisiaj?" nie zostanie dopasowane do zdania "pies **jest** bardzo szczliwy" - usunlimy wsp贸lny mianownik "jest".

Nie istnieje *uniwersalna* lista stopword贸w - podlinkuj [przykadow list dla jzyka polskiego](https://github.com/bieli/stopwords/blob/master/polish.stopwords.txt). 

#### Problematyka

Usuwanie stopword贸w ma swoje problemy:

1. Stopwordy r贸偶ni si w zale偶noci od jzyka. Gdybymy wykorzystali angielsk list stopword贸w w polskim zapytaniu do wyszukiwarki, to nie moglibymy znale藕 informacji o mostach - bowiem "most" to angielski stopword! Oznacza to, 偶e jeli tworzymy indeks BM25 operujcy na kilku jzykach, to **musimy poprawnie zidentyfikowa jzyk** przed doborem odpowiedniej listy. 
2. Stopwordy mog mie znaczenie semantyczne w zdaniu - m贸wic o "The Rock", chodzi nam o amerykaskiego aktora; m贸wic o "rock", chodzi nam o kamienie.  

Zwr贸c r贸wnie偶 uwag, 偶e usuwanie stopword贸w nie jest w 100% konieczne przy BM25. Algorytm wy偶ej punktuje unikalne sowa, wic przy dostatecznie du偶ej liczbie dokument贸w, powszechnie wystpujce stopwordy powinny by punktowane w niewielkim stopniu. Oznacza to w teorii, 偶e trafimy na niewaciwe dopasowania, ale o sabej punktacji.

Jak ze wszystkimi krokami: wprowad藕cie takie przetwarzanie dla swojego datasetu i **przetestujcie czy i jak wpyno na wyniki** :) 

#### Stemming i lematyzacja

Kluczowy problem - dla BM25, "pies", "psy" oraz "psach" to 3 r贸偶ne sowa! Rozpatrzmy nastpujce zdania:
- "kleszcz na psie"
- "poradnik: zwalczanie kleszczy u Twojego psa"

Zdania nie zostan dopasowane - "kleszcz" to nie "kleszczy", a "psie" to nie "psa". 

Dwie metody, kt贸re mog rozwiza ten problem, to stemming i lematyzacja.

**Stemming** polega na wydobyciu ze sowa rdzenia, czyli obcicie koc贸wki fleksyjnej. Wynikiem nie jest poprawne sowo:

```python
stemmer('teraz') == 'teraz'
stemmer('przeszywajco') == 'przeszywa'
stemmer('krzyczaa') == 'krzy'
stemmer('kobiety') == 'kobiet'
stemmer('kobietom') == 'kobiet'
stemmer('kobieta') == 'kobiet'
``` 

**Lematyzacja** polega na wydobyciu formy podstawowej, czyli np. bezokolicznika dla czasownik贸w czy liczby pojedynczej rzeczownika:

```python
lemmatization('teraz') == 'teraz'
lemmatization('przeszywajco') == 'przeszywa'
lemmatization('krzyczaa') == 'krzycze'
lemmatization('kobiety') == 'kobieta'
```

Lematyzacja jest bardziej zasobo偶erna od stemmingu, jednak przewa偶nie osiga lepsze wyniki. Dla jzyka polskiego mo偶emy zastosowa m.in. [PoLemma](https://huggingface.co/amu-cai/polemma-large) do lematyzacji oraz [Stempel](https://github.com/dzieciou/pystempel) do stemmingu.

Wracajc do przykadu - po zastosowaniu lematyzacji, nasz algorytm BM25 bdzie w stanie dopasowa zdania:
- "kleszcz na psie" > "**kleszcz** na **pies**"
- "poradnik: zwalczanie kleszczy u Twojego psa" > "poradnik: zwalczy **kleszcz** u tw贸j **pies**"

#### Polskie znaki, interpunkcja

Wspomn r贸wnie偶 o tym, 偶e w pre-processingu mo偶emy usuwa polskie znaki, co wyeliminuje niedopasowania pomidzy "za偶贸 gl ja藕" a "zazolc gesla jazn". Jednak - jeli dodamy ten krok przetwarzania, to sowo "o" zacznie by powizane z loteryjnym "los". Co za co!

{{< img src="bralczyk.jpg" caption="Tematyczny boomerski 偶arcik">}}

#### Liter贸wki i synonimy

BM25 nie powi偶e sowa "pies" z sowem "peis"; nie powi偶e r贸wnie偶 sowa "auto" ze sowem "samoch贸d".

Na moment pisania artykuu nie znam rozwizania ;) Dla synonim贸w mo偶e si przyda [wyszukiwanie semantyczne](/blog/embeddingi), ale to nie jest stricte BM25.

### Implementacja BM25 

#### Jak stworzy indeks BM25?

BM25 ma wiele implementacji w Pythonie, w szczeg贸lnoci:
- [rank-bm25](https://pypi.org/project/rank-bm25/) jest najbardziej popularn, ale nie jest najlepsza;
- znacznie lepszym wyborem bdzie [bm25s](https://github.com/xhluca/bm25s), kt贸ra jest kilkaset razy szybsza od `rank-bm25` i wspiera m.in. zapisywanie indeksu w memory-mapped plikach

Alternatywnie mo偶emy zastosowa bazy danych - osobicie polecam [ParadeDB](https://www.paradedb.com/), kt贸re jest Postgresem z doinstalowanym rozszerzeniem `pg_search`, kt贸re umo偶liwia [indeksowanie BM25](https://docs.paradedb.com/documentation/full-text/scoring) na kolumnie tekstowej. Rozszerzenie r贸wnie偶 [umo偶liwia bardziej skomplikowane zapytania](https://docs.paradedb.com/api-reference/full-text/overview). Projekt jest objty licencj AGPL v3.0. 

Alternatywy, kt贸rych osobicie nie testowaem, to [ElasticSearch](https://www.elastic.co/blog/practical-bm25-part-1-how-shards-affect-relevance-scoring-in-elasticsearch) oraz [Weaviate](https://weaviate.io/developers/weaviate/search/bm25).

{{< notice-feather-icons tip >}}
Jeli wybrana przez Was baza/rozwizanie nie wspiera odpowiedniego pre-processingu, zaimplementujcie je po stronie aplikacji i przekazujcie do indeksu BM25 ju偶 przetworzone dokumenty.  
{{</ notice-feather-icons >}}

#### Benchmark 

Przed rozpoczciem pracy [powiniene stworzy benchmark trafnoci](#todo) Twojej wyszukiwarki, z wybranymi metrykami, np. recall@3 / recall@5.  To umo偶liwi Wam ustali, czy wprowadzone zmiany polepszaj, czy pogarszaj jako Waszej aplikacji - nie wierzcie intuicji!

```python
recall_a = test_recall_bm25_bez_preprocessingu(test_set)
# 85%
recall_b = test_recall_bm25_z_niestosownym_preprocessingiem(test_set)
# 67%

# Recall mo偶e si pogorszy!
```
### Reading list

- [Better Sparse Retrieval: Extending BM25 With Subwords, Evan Harris](https://medium.com/@emitchellh/extending-bm25-with-subwords-30b334728ebd) - artyku przedstawiajcy ulepszenia do BM25, z konceptem wykorzystania tiktoken jako alternatyw do stemmingu;
-  [Understanding TF-IDF and BM-25, Rudi Seitz](https://kmwllc.com/index.php/2020/03/20/understanding-tf-idf-and-bm-25/) - wietne wytumaczenie r贸偶nic midzy TF/IDF a BM25;
- [Polish NLP Resources, Sawomir Dadas](https://github.com/sdadas/polish-nlp-resources/), lista zasob贸w NLP w jzyku polskim
- [Stop Stopping](https://vectara.com/blog/stop-stopping/) - o usuwaniu stopword贸w
- [Czym jest NLP?](https://pogromcykodu.pl/czym-jest-nlp/) - 藕r贸do przykad贸w dla stemming vs lematyzacja
- [What Are Stemming and Lemmatization?, IBM](https://www.ibm.com/topics/stemming-lemmatization) - stemming vs lematyzacja

TODO: napraw linki (todo)
TODO: ty/wy
TODO: ona/on