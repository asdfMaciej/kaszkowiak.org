---
title: "BM25: wyszukiwanie po sowach kluczowych"
date: 2024-10-16T00:00:00+02:00
lastmod: 2024-10-16T00:00:00+02:00
summary: "Ulepsz wyszukiwanie w swojej aplikacji! Wdr贸偶 BM25: odkryj jak dziaa, poznaj problemy i praktyczne porady "
thumbnail: "thumbnail.png"
tags: ["nlp", "rag", "retrieval", "ulepsz swoje AI", "ai", "python"]
---

## Co to BM25?

BM25 to funkcja, kt贸ra punktuje dopasowanie dokument贸w do zapytania u偶ytkownika. Jeli sowa w zapytaniu znajduj si w dokumencie, to dokument otrzyma punkty. 

BM25 przyda si wszdzie tam, gdzie potrzebujemy wyszukiwanie po sowach kluczowych. Jest wykorzystywane jako [domylny algorytm ElasticSearch](https://www.elastic.co/blog/practical-bm25-part-2-the-bm25-algorithm-and-its-variables) czy w [aplikacjach RAG](/blog/retrieval-augmented-generation) do wyszukiwania hybrydowego w poczeniu z [embeddingami](/blog/embeddingi).

Zrozumienie mechanizmu dziaania oraz sztuczek zwizanych z implementacj jest niezwykle przydatne - w szczeg贸lnoci dla jzyka polskiego!

{{< img src="wykres.png" caption="BM25 ulepsza wyszukiwanie semantyczne, src: Azure AI">}}

### Jak dziaa BM25?

Algorytm analizuje **czsto wystpowania poszczeg贸lnych s贸w kluczowych** w zbiorze dokument贸w.   

{{< img src="wzor.png" caption="Wz贸r BM25">}}

Wz贸r mo偶e by przytaczajcy ;) **Wytumacz co z niego wynika**, a zainteresowanych formaln postaci odsyam do [Wikipedii](https://en.wikipedia.org/wiki/Okapi_BM25) oraz wietnego [artykuu por贸wnujcego TF/IDF i BM25](https://kmwllc.com/index.php/2020/03/20/understanding-tf-idf-and-bm-25/). 

#### Najwa偶niejsze zasady dziaania

Dokumenty oraz zapytania w pierwszej kolejnoci dzielone s na termy: przyjmijmy, 偶e 1 sowo to 1 term. [1]  

Im rzadziej dopasowane sowa wystpuj w dokumentach, tym bardziej bd punktowane: 
- Jeli np. przeszukujemy zasoby ksigarni, to dla zapytania "ksi偶ka eklektyzm", dopasowania do rzadziej wystpujcego sowa "eklektyzm" bd bardziej punktowane ni偶 do sowa "ksi偶ka".
- Pospolite sowa bd znacznie mniej punktowane: np. w zdaniu "*co na* **obiad**", dopasowanie do "*co* wrzuci *na* grilla" bdzie znacznie sabsze ni偶 "pomysy na **obiad**" 

Im sowo czciej bdzie wystpowao w dokumencie, tym dokument otrzyma wiksz liczb punkt贸w. Dziki temu, dla zapytania "kot" bdzie bardziej punktowany artyku o kotach, ni偶 encyklopedia wymieniajaca wszystkie zwierzta:
- artyku wymieni "kot" 20 razy, majc 2 strony tekstu
- encyklopedia wymieni "kot" 30 razy, ale na 100 stron tekstu 

BM25 ignoruje r贸wnie偶 wzgldn pozycj s贸w w dokumencie. Dla zdania: 
- "gdzie jest **czerwony so?**"

Poni偶sze zdania bd miay identyczne dopasowania:
- "**czerwony** notatnik, czarny **so**" 
- "**czerwony so**, czarny notatnik"

Ka偶de sowo jest rozpatrywane indywidualnie.

{{< notice-feather-icons info >}}
[1] Dokumenty de facto s **dzielone na termy** - przewa偶nie to s sowa, ale r贸wnie dobrze mo偶emy wykorzysta inny podzia.

1. Mo偶emy dzieli dokumenty na `n-gramy`, kt贸re grupuj sowa razem:
- `bi-gramy` to poczenia dw贸ch s贸w
- `tri-gramy` to poczenia trzech s贸w

To rozwizuje problem wczeniej wymienionego *czerwonego sonia*! 

2. Mo偶emy dzieli dokumenty na tokeny z wykorzystaniem np. tokenizera `tiktoken`

To zmniejsza konieczno wykorzystywania stemmingu / lematyzacji (o tym za chwil).

Oba podejcia maj swoje trade-offy, wic zainteresowanych odsyam do Google i eksperyment贸w ;)
{{</ notice-feather-icons >}}

## Pre-processing: klucz do dobrych wynik贸w

BM25 dla skutecznego dziaania wymaga pre-processingu danych wejciowych. Przedstawi na przykadach istotne kroki:

### Lowercasing 

BM25 domylnie jest **case-sensitive**: rozr贸偶nia pomidzy du偶ymi a maymi znakami.  Token "**C**zerwony" nie bdzie powizany z tokenem "**c**zerwony". 

Czy to jest po偶dane w Twojej aplikacji? Jeli nie, to **zamiana tekstu na mae znaki (*lowercasing*)** wyeliminuje ten problem. Jednak jeli np. przetwarzasz kody seryjne, kt贸re rozr贸偶niaj mae i du偶e znaki, i chciaby umo偶liwi ich precyzyjne wyszukiwanie, to wprowadzenie lowercasingu mo偶e pogorszy wyniki! 

Std zawsze warto si zastanowi: czy chcemy wprowadzi pre-processing?     

```python
# Przed zmianami
documents = ["Soce jest zielone"]
query = "Jakiego koloru jest soce"
search_bm25(documents, query) == []
# Brak dokument贸w - Soce vs soce

# Po zmianach
documents = ["soce jest zielone"]
query = "jakiego koloru jest soce"
search_bm25(documents, query) == ["soce jest zielone"] 
# Match na sowie soce
```

{{< notice-feather-icons note >}}
Zauwa偶, 偶e dane wejciowe musz by przetworzone w identyczny spos贸b, co dane dokument贸w w indeksie. Jeli np. chcemy usun polskie znaki - to musimy to robi zar贸wno dla zapytania u偶ytkownika, jak i dokument贸w. To tyczy si ka偶dego kroku.
{{</ notice-feather-icons >}}

### Usuwanie stopword贸w

{{< notice-feather-icons info >}}
Stopwordy to sowa powszechnie wystpujce w danym jzyku, na przykad: "to", "w", "jak", "z", "na".
{{</ notice-feather-icons >}}

Usuwanie stopword贸w sprawia, 偶e najczciej wystpujce sowa w danym jzyku zostan usunite: 

```python
remove_stopwords("jaka jest pogoda dzisiaj?") == "pogoda dzisiaj?"
remove_stopwords("pies jest bardzo szczliwy") == "pies szczliwy"
```

Po usuniciu stopword贸w, zdanie "jaka **jest** pogoda dzisiaj?" nie zostanie dopasowane do zdania "pies **jest** bardzo szczliwy" - usunlimy wsp贸lny mianownik "jest".

Nie istnieje *uniwersalna* lista stopword贸w - podlinkuj [przykadow list dla jzyka polskiego](https://github.com/bieli/stopwords/blob/master/polish.stopwords.txt). 

#### Problematyka

Usuwanie stopword贸w ma swoje problemy:

1. Stopwordy r贸偶ni si w zale偶noci od jzyka. Gdybymy wykorzystali angielsk list stopword贸w w polskim zapytaniu do wyszukiwarki, to nie moglibymy znale藕 informacji o mostach - bowiem "most" to angielski stopword! Oznacza to, 偶e jeli tworzymy indeks BM25 operujcy na kilku jzykach, to **musimy poprawnie zidentyfikowa jzyk** przed doborem odpowiedniej listy. Analogicznie z zapytaniami u偶ytkownika.
2. Stopwordy mog mie znaczenie semantyczne w zdaniu - m贸wic o "The Rock", chodzi nam o amerykaskiego aktora; m贸wic o "rock", chodzi nam o kamienie.  

Ponadto: usuwanie stopword贸w nie jest konieczne przy BM25. Algorytm wy偶ej punktuje unikalne sowa, wic przy dostatecznie du偶ej liczbie dokument贸w, powszechnie wystpujce stopwordy bd punktowane w niewielkim stopniu. Niewaciwe dopasowania bd miay nisk punktacj.

Jak ze wszystkimi krokami: wprowad藕 takie przetwarzanie dla swojego datasetu i **przetestuj jak wpyno na wyniki** :) 

### Stemming i lematyzacja

Kluczowy problem - dla BM25, "pies", "psy" oraz "psach" to 3 r贸偶ne sowa! Rozpatrzmy nastpujce zdania:
- "kleszcz na psie"
- "poradnik: zwalczanie kleszczy u Twojego psa"

Zdania nie zostan dopasowane - "kleszcz" to nie "kleszczy", a "psie" to nie "psa". 

Dwie metody, kt贸re mog rozwiza ten problem, to stemming i lematyzacja.

**Stemming** polega na wydobyciu ze sowa rdzenia, czyli obcicie koc贸wki fleksyjnej. Wynikiem niekoniecznie jest poprawne sowo, ale umo偶liwia to por贸wnywanie zbli偶onych s贸w:

```python
stemmer('teraz') == 'teraz'
stemmer('przeszywajco') == 'przeszywa'
stemmer('krzyczaa') == 'krzy'
stemmer('kobiety') == 'kobiet'
stemmer('kobietom') == 'kobiet'
stemmer('kobieta') == 'kobiet'
``` 

**Lematyzacja** polega na wydobyciu formy podstawowej, czyli np. bezokolicznika dla czasownik贸w czy liczby pojedynczej rzeczownika:

```python
lemmatization('teraz') == 'teraz'
lemmatization('przeszywajco') == 'przeszywa'
lemmatization('krzyczaa') == 'krzycze'
lemmatization('kobiety') == 'kobieta'
```

Lematyzacja jest bardziej zasobo偶erna od stemmingu, jednak przewa偶nie osiga lepsze wyniki. Dla jzyka polskiego mo偶emy zastosowa m.in. [PoLemma](https://huggingface.co/amu-cai/polemma-large) do lematyzacji oraz [Stempel](https://github.com/dzieciou/pystempel) do stemmingu.

Wracajc do przykadu - po zastosowaniu lematyzacji, nasz algorytm BM25 bdzie w stanie dopasowa zdania:
- "kleszcz na psie" > "**kleszcz** na **pies**"
- "poradnik: zwalczanie kleszczy u Twojego psa" > "poradnik: zwalczy **kleszcz** u tw贸j **pies**"

### Usuwanie polskich znak贸w

W pre-processingu mo偶emy tak偶e usuwa polskie znaki, co wyeliminuje niedopasowania pomidzy "za偶贸 gl ja藕" a "zazolc gesla jazn". Jednak - jeli dodamy ten krok przetwarzania, to sowo "o" zacznie by powizane z loteryjnym "los". Co za co!

{{< img src="bralczyk.jpg" caption="Tematyczny boomerski 偶arcik">}}

### Liter贸wki i synonimy

BM25 nie powi偶e sowa "pies" z sowem "peis"; nie powi偶e r贸wnie偶 sowa "auto" ze sowem "samoch贸d". Na moment pisania artykuu nie znam rozwizania, ale zakrelam problem ;)

## Implementacja BM25 

Na przykadzie Pythona - mo偶esz zastosowa jedn z gotowych bibliotek, w szczeg贸lnoci:
- [rank-bm25](https://pypi.org/project/rank-bm25/) jest najbardziej popularn bibliotek, ale nie jest najlepsza;
- znacznie lepszym wyborem bdzie [bm25s](https://github.com/xhluca/bm25s), kt贸ra jest kilkaset razy szybsza od `rank-bm25` i wspiera m.in. zapisywanie indeksu w memory-mapped plikach

R贸wnie dobr opcj jest indeks w bazie danych - osobicie polecam [ParadeDB](https://www.paradedb.com/), kt贸re jest Postgresem z doinstalowanym rozszerzeniem `pg_search`, kt贸re umo偶liwia [indeksowanie BM25](https://docs.paradedb.com/documentation/full-text/scoring) na kolumnie tekstowej. Rozszerzenie r贸wnie偶 [umo偶liwia bardziej skomplikowane zapytania](https://docs.paradedb.com/api-reference/full-text/overview). Projekt jest objty licencj AGPL v3.0. 

Inne znane mi bazy danych z wsparciem dla BM25, kt贸rych jednak nie testowaem, to [ElasticSearch](https://www.elastic.co/blog/practical-bm25-part-1-how-shards-affect-relevance-scoring-in-elasticsearch) oraz [Weaviate](https://weaviate.io/developers/weaviate/search/bm25).

{{< notice-feather-icons tip >}}
Jeli wybrana przez Ciebie baza/biblioteka nie wspiera odpowiedniego pre-processingu, zaimplementuj przetwarzanie po stronie aplikacji i przekazuj do indeksu BM25 ju偶 przetworzone dokumenty.  
{{</ notice-feather-icons >}}

### Pamitaj o benchmarkach 

Pamitaj, aby przed rozpoczciem pracy [stworzy benchmark trafnoci](/blog/testowanie-ai) Twojej wyszukiwarki, z wybranymi metrykami, np. recall@3 / recall@5.  To umo偶liwi Ci ustali, czy wprowadzone zmiany polepszaj, czy pogarszaj jako Waszej aplikacji - nie wierz intuicji!

```python
recall_a = test_recall_bm25_bez_preprocessingu(test_set)
# 85%
recall_b = test_recall_bm25_z_niestosownym_preprocessingiem(test_set)
# 67%

# Wniosek: wersja A > wersja B
```
## Sowa kocowe i odnoniki

Mam nadziej, 偶e post okaza si pomocny :) Jeli chcesz przeczyta wicej artyku贸w w tej tematyce, zostawiam Ci list:

- [Better Sparse Retrieval: Extending BM25 With Subwords, Evan Harris](https://medium.com/@emitchellh/extending-bm25-with-subwords-30b334728ebd) - artyku przedstawiajcy ulepszenia do BM25, z konceptem wykorzystania tiktoken jako alternatyw do stemmingu;
- [Understanding TF-IDF and BM-25, Rudi Seitz](https://kmwllc.com/index.php/2020/03/20/understanding-tf-idf-and-bm-25/) - wietne wytumaczenie r贸偶nic midzy TF/IDF a BM25;
- [Polish NLP Resources, Sawomir Dadas](https://github.com/sdadas/polish-nlp-resources/), lista zasob贸w NLP w jzyku polskim
- [Stop Stopping](https://vectara.com/blog/stop-stopping/) - o usuwaniu stopword贸w
- [Czym jest NLP?](https://pogromcykodu.pl/czym-jest-nlp/) - 藕r贸do przykad贸w dla stemming vs lematyzacja
- [What Are Stemming and Lemmatization?, IBM](https://www.ibm.com/topics/stemming-lemmatization) - stemming vs lematyzacja

Jeli dostrzegasz jakie bdy, niecisoci, lub chcia\*by po prostu porozmawia o tej tematyce - zapraszam do kontaktu na [LinkedInie](https://www.linkedin.com/in/maciej-kaszkowiak/) lub e-mailowego - adres znajdziesz w stopce :)
