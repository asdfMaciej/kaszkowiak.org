---
title: "EnsembleAI: zabezpieczenia ML kontra 5 studentÃ³w"
date: 2024-03-18T20:00:00+02:00
lastmod: 2024-03-18T20:00:00+02:00
summary: "Relacja z hackathonu EnsembleAI z 16-17 marca 2024, opartego o tematykÄ™ security w ML. Czy ekipa poczÄ…tkujÄ…cych podoÅ‚a zadaniom?"
thumbnail: "druzyna.jpg"
tags: ["hackathon", "ai", "ml", "security"]
slug: "ensemble-ai"
---

W miniony weekend skompletowaÅ‚em druÅ¼ynÄ™ znajomych z GHOSTa i ruszyliÅ›my na bÃ³j do Warszawy, aby walczyÄ‡ z zabezpieczeniami modelÃ³w sztucznej inteligencji. Relacja pisana okiem poczÄ…tkujÄ…cego ;d 

## Co trzeba byÅ‚o zrobiÄ‡?

Zadania opieraÅ‚y siÄ™ o tematykÄ™ zabezpieczeÅ„ modelÃ³w ML.

**W pierwszym zadaniu musieliÅ›my wykraÅ›Ä‡ wagi modelu dostÄ™pnego za API.** WysyÅ‚ajÄ…c zapytanie, w odpowiedzi na obraz PNG 32x32 otrzymywaliÅ›my reprezentacjÄ™ w postaci wektora z 512 pozycjami. MieliÅ›my rÃ³wnieÅ¼ dostÄ™p do niewielkiej czÄ™Å›ci obrazÃ³w zawartych w training secie enkodera. OczekiwanÄ… odpowiedziÄ… na zadanie byÅ‚ model zwracajÄ…cy identyczne wagi do tego zamieszczonego w API. 

Aby nie byÅ‚o za prosto, organizatorzy wdroÅ¼yli kilka zabezpieczeÅ„:
- wyniki w API byÅ‚y z kaÅ¼dym zapytaniem coraz bardziej zaszumiane;
- nie mieliÅ›my pojÄ™cia jakiej architektury jest wykradany model;
- serwery organizatorÃ³w pÅ‚onÄ™Å‚y przez \~poÅ‚owÄ™ hackathonu ;) 

Jak moÅ¼na obejÅ›Ä‡ szum rosnÄ…cy z liczbÄ… zapytaÅ„ do API? W prawdziwym Å›wiecie: stworzyÄ‡ wiÄ™cej kont! Nowe konto usunie nam szum w pÃ³Åºniejszych zapytaniach.

Organizatorzy poszli tym tropem i **drugie zadanie polegaÅ‚o na zÅ‚amaniu nowego zabezpieczenie przeciwko atakowi z wielu kont**, czyli tak zwany Sybil attack. 

Jak dziaÅ‚a takie zabezpieczenie? Otrzymywane wektory od teraz byÅ‚y tak zmodyfikowane, aby:
- atakujÄ…cy nie mÃ³gÅ‚ jednoczeÅ›nie zastosowaÄ‡ wektorÃ³w z dwÃ³ch kont do jednego ataku; 
- a wektory po transformacjach bÄ™dÄ… rÃ³wnie uÅ¼yteczne dla zastosowaÅ„ uÅ¼ytkownika, co oryginalne.

KaÅ¼dy uczestnik mÃ³gÅ‚ wykonaÄ‡ maksymalnie 2 000 zapytaÅ„ dla jednego zestawu przeksztaÅ‚ceÅ„. OczekiwanÄ… odpowiedziÄ… na zadanie byÅ‚o komplet oryginalnych wektorÃ³w dla 20 000 zdjÄ™Ä‡ :) Zadanie byÅ‚o rozbite na dwa punkty, kaÅ¼dy z odrÄ™bnÄ… metodÄ… zabezpieczeÅ„.

Co za tym idzie, **w trzecim zadaniu musieliÅ›my stworzyÄ‡ wÅ‚asny mechanizm zabezpieczeÅ„**. OtrzymaliÅ›my zestaw wektorÃ³w, ktÃ³ry powinniÅ›my zabezpieczyÄ‡ i przesÅ‚aÄ‡ zmodyfikowane wektory. Maszynka sprawdzajÄ…ca upewniaÅ‚a siÄ™, Å¼e wektory nadajÄ… siÄ™ do uÅ¼ytku i nie tracÄ… na skutecznoÅ›ci. JeÅ›li byÅ‚y OK, druÅ¼yny byÅ‚y punktowane po odlegÅ‚oÅ›ci wzglÄ™dem oryginalnych wektorÃ³w - im ustalono mniejsze podobieÅ„stwo, tym lepszy wynik. 

Zadania byÅ‚y skonstruowane w taki sposÃ³b, Å¼e byÅ‚y niezaleÅ¼ne od siebie. Nie musieliÅ›my skoÅ„czyÄ‡ zadania pierwszego, aby zaczÄ…Ä‡ drugie, etc. :)

## Jak duÅ¼y byÅ‚ prÃ³g wstÄ™pu?

Z perspektywy osoby poczÄ…tkujÄ…cej, poczÄ…tkowo ogÅ‚oszony temat "stealing SSL encoders" zmroziÅ‚ krew w moich Å¼yÅ‚ach. Skoro nie pojmujÄ™ czym sÄ… nazwy SSL, encoder, to jak mam takowy wykraÅ›Ä‡? 

Na szczÄ™Å›cie, organizatorzy przed wydarzeniem opublikowali krÃ³tki wstÄ™p teoretyczny dla zadaÅ„, ktÃ³ry rozjaÅ›niÅ‚ tematykÄ™:

{{< youtube yUiCHiPHUpc >}}

Oraz:

{{< youtube 7-pfbGBZhIg >}}

Bardzo pomogÅ‚y mi takÅ¼e poniÅ¼sze prace naukowe, ktÃ³re namierzyÅ‚em z odrobinÄ… Google-fu:

- zrozumienie konceptu - w gÅ‚Ã³wnej mierze [Stealing Machine Learning Models via Prediction APIs](https://arxiv.org/abs/1609.02943)
- zrozumienie konceptu - drugorzÄ™dnie [On the Difficulty of Defending Self-Supervised Learning against Model](https://arxiv.org/abs/2205.07890)
- zrozumienie zastosowanego zabezpieczenia w zadaniu 1 - [Bucks for Buckets (B4B): Active Defenses Against Stealing Encoders](https://arxiv.org/abs/2310.08571)

Ale to wszystko teoria. Po przeczytaniu paperÃ³w nie miaÅ‚em pojÄ™cia, czy moja wiedza wystarczy, czy implementacja totalnie nas pokona. Reszta teamu podobnie. Jak oceniamy ten aspekt po wydarzeniu? 

**PrÃ³g wstÄ™pu okazaÅ‚ siÄ™ niewielki** :) Do zrobienia wszystkich zadaÅ„ wystarczyÅ‚y opanowane podstawy podstaw (np. pierwsze 2-3 lekcje z [course.fast.ai](https://course.fast.ai)) oraz zaciekÅ‚oÅ›Ä‡ do nauki i eksperymentowania. No, i nie zapominajmy o walce z PyTorchem ;)

## Jak rozwiÄ…zaliÅ›my zadania? 

Opowiem w pokrÄ™tnej kolejnoÅ›ci: 

### Trzecie - Å‚atwo

**Zadanie trzecie okazaÅ‚o siÄ™ najprostsze**. Aby zabezpieczyÄ‡ wektor, zachowujÄ…c pierwotnÄ… skutecznoÅ›Ä‡, wykorzystaliÅ›my poniÅ¼szy giga-skomplikowany hipertajnyâ„¢ kod. OpatrzyÅ‚em go komentarzami, aby rozszyfrowanie byÅ‚o moÅ¼liwe: 

```python
# Load the input data.
data = np.load("DefenseTransformationSubmit.npz")['representations']

# Generate a permutation of indices
perm = np.random.default_rng().permutation(len(data[0]))

# Shuffle each array using the permutation
shuffled_arrays = np.array([arr[perm] for arr in data])

# Save the submission
data = np.savez("submission.npz",representations=shuffled_arrays)
```

PotasowaliÅ›my tablice i... to tyle xD UzyskaliÅ›my Å‚adny wynik w Å›rodku stawki. PuÅ›ciÅ‚em kod znowu, aby uzyskaÄ‡ inne losowe potasowanie, i... uzyskaliÅ›my jeszcze lepszy wynik 8) 

Wynik: #9/27 

MieliÅ›my w planach pomysÅ‚y na kolejne zabezpieczenia, ale nie byliÅ›my w stanie ich przetestowaÄ‡. WysyÅ‚ka rozwiÄ…zaÅ„ byÅ‚a niemoÅ¼liwa od \~ pierwszej w nocy do koÅ„ca wydarzenia (API on fire), a my zaczÄ™liÅ›my dziaÅ‚aÄ‡ chwilÄ™ przed pÃ³Å‚nocÄ…. (\*) Organizatorzy przygotowali moÅ¼liwoÅ›Ä‡ wysÅ‚ania jednego rozwiÄ…zania, ktÃ³re byÅ‚o rÄ™cznie ocenione po zakoÅ„czeniu wydarzenia, ale to niestety nie wystarczyÅ‚o. Z pomysÅ‚Ã³w mieliÅ›my jeszcze pomnoÅ¼enie wektora o staÅ‚Ä… wartoÅ›Ä‡ oraz dodanie staÅ‚ego czynnika.

### Pierwsze - ciÄ™Å¼ko

#### WyÅ›lijmy cokolwiek

Aby zrobiÄ‡ pierwsze zadanie, trzeba zrozumieÄ‡ jak wykradany model byÅ‚ trenowany. Enkoder, ktÃ³ry zwracaÅ‚ w API wektory dla obrazkÃ³w, to ostatnia warstwa stojÄ…ca przed modelem klasyfikacji. 

ChcieliÅ›my wysÅ‚aÄ‡ na start cokolwiek. StworzyliÅ›my lokalnie model klasyfikatora z poniÅ¼szymi cechami:
- przedostatnia warstwa miaÅ‚a 512 neuronÃ³w (wymagana szerokoÅ›Ä‡ enkodera);
- ostatnia warstwa miaÅ‚a 20 neuronÃ³w (liczba klas)

 Po wytrenowaniu modelu klasyfikatora na parach (obrazek, label), musieliÅ›my jakoÅ› wydobyÄ‡ przedostatniÄ… warstwÄ™, aby ona byÅ‚a koÅ„cowa przy wysyÅ‚ce. PomÃ³gÅ‚ nam jeden z organizatorÃ³w, wielkie dziÄ™ki! ZamieniliÅ›my ostatniÄ… warstwÄ™ na nn.Linear, ktÃ³ra zwracaÅ‚a niezmieniony wektor z przedostatniej warstwy. Tym sposobem otrzymaliÅ›my model, ktÃ³ry speÅ‚niaÅ‚ wymagania zadania. WysÅ‚aliÅ›my go szybko po tym, jak API wstaÅ‚o, i... byliÅ›my pierwsi! XD

{{< img src="pierwsi.png" alt="Es?" >}} 

OczywiÅ›cie przy Å›miesznym wyniku. Nasze wagi nie byÅ‚y w Å¼aden sposÃ³b powiÄ…zane z wagami docelowego klasyfikatora, chociaÅ¼by przez kolejnoÅ›Ä‡.

#### WyÅ›lijmy cokolwiek dziaÅ‚ajÄ…cego 

API wstaÅ‚o, wiÄ™c postanowiliÅ›my faktycznie wykraÅ›Ä‡ model.

ZacznÄ™ od wytÅ‚umaczenia - jak wykraÅ›Ä‡ model? Bierzecie duÅ¼o inputÃ³w (w tym przypadku obrazÃ³w), otrzymujecie duÅ¼o outputÃ³w (w tym przypadku wektorÃ³w) i trenujecie wÅ‚asnÄ… sieÄ‡ neuronowÄ…. Otrzymacie model, ktÃ³ry zachowuje siÄ™ w zbliÅ¼ony sposÃ³b do oryginaÅ‚u. 

Aby polepszyÄ‡ wynik, postanowiliÅ›my zebraÄ‡ jak najwiÄ™cej inputÃ³w w postaci (input - zdjÄ™cie, output API - wektor), a nastÄ™pnie wytrenowaÄ‡ lokalnÄ… sieÄ‡ na tych parach, kompletnie pomijajÄ…c klasyfikacjÄ™ obrazkÃ³w.

Z drobnÄ… pomocÄ… Copilota, udaÅ‚o siÄ™! Wynik spadÅ‚ o caÅ‚y rzÄ…d wielkoÅ›ci, a w tym zadaniu im mniejszy tym lepszy :) 

PostanowiliÅ›my wiÄ™c pobraÄ‡ wiÄ™cej danych. Tutaj duÅ¼e zaskoczenie. Wynik dla 97 wykradzionych par okazaÅ‚ siÄ™ lepszy, niÅ¼ dla 1900 par. Z kolejnymi pobieranymi obrazkami, API nakÅ‚adaÅ‚o coraz wiÄ™kszy szum.  

#### Ulepszmy to 

Logicznym pierwszym krokiem byÅ‚o dla nas obejÅ›cie szumu. Nie mieliÅ›my jednak pojÄ™cia, jak to dziaÅ‚a pod spodem w API (w koÅ„cu black box) - wziÄ™liÅ›my wiÄ™c kartkÄ™ papieru i rozpatrzyliÅ›my moÅ¼liwe warianty:

PoczÄ…tkowo przyjÄ…Å‚em, Å¼e nowe, mocniejsze ustawienia szumu sÄ… generowane wraz z poszerzeniem przestrzeni zapytaÅ„ z API i nie sÄ… modyfikowane przy zapytaniach z dotychczasowej przestrzeni. Zapytania `x1 x2 x3` o obrazek `A A A` spowodowaÅ‚yby uzyskanie identycznych danych `x1 = x2 = x3`. Natomiast zapytania `y1 y2 y3` o obrazki `A B A` spowodowaÅ‚yby uzyskanie odmiennych danych dla `y1 != y3`, przy czym `y3` byÅ‚oby wygenerowane z wiÄ™kszÄ… wartoÅ›ciÄ… szumu. 

To chyba byÅ‚oby caÅ‚kiem dobre zabezpieczenie. Aby uzyskaÄ‡ 100 zaszumionych prÃ³bek dla wektora A, musielibyÅ›my wykonaÄ‡ 100+99+98+...1 zapytaÅ„ w nastÄ™pujÄ…cym schemacie:
```
A | B A | C B A | D C B A | ...
```

UstaliliÅ›my jednak, Å¼e tak nie jest. Zapytanie `A A A` spowodowaÅ‚o uzyskanie trzech rÃ³Å¼nych wektorÃ³w. Co za tym idzie? **Szum moÅ¼na usunÄ…Ä‡ w prosty sposÃ³b**, czyli odpytujÄ…c N razy z kolei o jednÄ… prÃ³bkÄ™, a nastÄ™pnie wyciÄ…gajÄ…c Å›redniÄ… arytmetycznÄ…. 

SprawdÅºmy to. EliminacjÄ™ szumu zmierzyÅ‚em odpytujÄ…c N razy `A`, nastÄ™pnie `B`, a finalnie `A`. Po uÅ›rednieniu pierwszego i trzeciego zbioru zapytaÅ„, zmierzyÅ‚em MSE pomiÄ™dzy Å›redniÄ… wektora ze zbioru nr 1, a Å›redniÄ… wektora ze zbioru nr 3. PrzetestowaÅ‚em dla rÃ³Å¼nych N i... metoda zadziaÅ‚aÅ‚a :)

**Szum byÅ‚ 2 rzÄ™dy wielkoÅ›ci mniejszy** porÃ³wnujÄ…c N=2 a N=100, a porÃ³wnujÄ…c N=2 a N=10 byÅ‚ 1 rzÄ…d wielkoÅ›ci mniejszy.

WpadÅ‚em wiÄ™c na pomysÅ‚, aby kompletnie olaÄ‡ obrazki z bazy i stworzyÄ‡ obrazki dla rÃ³wnomiernie rozdystrybuowanych punktÃ³w z przestrzeni zapytaÅ„. W teorii powinno przynieÅ›Ä‡ to gigantyczny szum (przez specyfikÄ™ zabezpieczeÅ„), ale w praktyce byÅ‚em w stanie go wyeliminowaÄ‡ w znaczÄ…cym stopniu. Jak wybraÄ‡ losowe obrazki w rozkÅ‚adzie rÃ³wnomiernym? `torch.randint` i konwersja na PNG :)

Metoda zadziaÅ‚aÅ‚a! O dziwo, model wytrenowany w oparciu o odszumione losowe punkty, poradziÅ‚ sobie lepiej.   

Niestety, ale przez ser\*er nie byÅ‚em w stanie przetestowaÄ‡ kolejnych pomysÅ‚Ã³w. Moimi kolejnymi krokami byÅ‚o zastosowanie metody eliminacji szumu na obrazkach ze zbioru treningowego, co pozwoliÅ‚oby mi otrzymaÄ‡ jeszcze lepszy wynik, poniewaÅ¼ specyfika zastosowanego zabezpieczenia sprawiaÅ‚a, Å¼e owe obrazki rezultowaÅ‚y mniejszym szumem. MyÅ›laÅ‚em rÃ³wnieÅ¼ nad wykorzystaniem jakoÅ› labelek ze zbioru testowego, ale nie wpadÅ‚em na Å¼aden dobry pomysÅ‚.   

Wynik: #15/27 (przedostatnie miejsce z druÅ¼yn, ktÃ³re wysÅ‚aÅ‚y rozwiÄ…zanie ğŸ˜)

### Drugie - magia

Zadanie drugie osiÄ…gnÄ™Å‚o nasze najlepsze wyniki! ByÅ‚o podzielone na dwie czÄ™Å›ci, nad ktÃ³rymi bezpoÅ›rednio nie pracowaÅ‚em przez podziaÅ‚ prac, wiÄ™c oddajÄ™ gÅ‚os Biniowi:

> Zacznijmy od tego, Å¼e zadanie opieraÅ‚o siÄ™ o tzw. Sybil attack, ktÃ³ry polega na tym, Å¼e gdy nie jesteÅ›my w stanie wykraÅ›Ä‡ wszystkich danych z jednego konta, to zakÅ‚adamy wiele kont, z kaÅ¼dego wykradamy odpowiedniÄ… czÄ™Å›Ä‡ danych i sklejamy je w caÅ‚oÅ›Ä‡. Tymczasem my po prostu wziÄ™liÅ›my dane z jednego zapytania, na nich wytrenowaliÅ›my modele i wyszÅ‚o, Å¼e jest z tego fajny efekt.
>
> Zadanie z sybil attackiem rozwiÄ…zaliÅ›my praktycznelie bez zastosowania sybil attacku. MieliÅ›my do dyspozycji 20000 obrazkÃ³w oraz dwa endpointy: A i B. 
>
> Po uderzeniu do endpointa, otrzymywaliÅ›my z powrotem reprezentacjÄ™ obrazka w postaci wektora o dÅ‚ugoÅ›ci 384. Problem polegaÅ‚ na tym, Å¼e mogliÅ›my zrobiÄ‡ to tylko dla 2000 obrazkÃ³w per endpoint (w przeciwnym wypadku trzeba zresetowaÄ‡ zadanie) zatem mieliÅ›my do dyspozycji tylko 10% datasetu (a nawet mniej bo przez serwery byÅ‚o to 1250). 
>
> Naszym celem byÅ‚o wykraÅ›Ä‡ przeksztaÅ‚cenie, jakie zachodzi miÄ™dzy wektorami zwracanymi przez B i A. Super data engineerowie Szymon i Maciej *[przyp. red. Mazur]* przygotowali dane, a ja z Benkiem napisaliÅ›my i wytrenowaliÅ›my dwa modele: pierwszy, Å¼eby wiedzieÄ‡ w jaki sposÃ³b generowane sÄ… 384-elementowe wektory dla obrazka, a drugi Å¼eby znaleÅºÄ‡ zaleÅ¼noÅ›Ä‡ miÄ™dzy wektorami z endpointÃ³w B oraz A. 
>
> No i wyszÅ‚o nam naprawdÄ™ nieÅºle, bo wytrenowaliÅ›my te modele i zajÄ™liÅ›my 6 miejsce w tym zadaniu z wariantem binarnym. Gorzej z wariantem affine, bo przez palÄ…cy siÄ™ serwer nie mieliÅ›my Å¼adnych sensownych danych. Co ciekawe, model z pierwszego podzadania, jakimÅ› cudem w drugim podzadaniu zajÄ…Å‚ 11 miejsce. 

Z mojej strony: team zrobiÅ‚ naprawdÄ™ dobrÄ… robotÄ™! Nie zapomnÄ™ ekscytacji, gdy okazaÅ‚o siÄ™ o 4 w nocy przy pierwszej wysyÅ‚ce, Å¼e nie doÅ›Ä‡ Å¼e model dziaÅ‚a, to jeszcze wbiÅ‚ siÄ™ do TOP 3 XD Sami nie wiemy, jak to siÄ™ staÅ‚o przy wykorzystaniu niewielkiej czÄ™Å›ci datasetu xD

Wynik: #6/27 oraz #11/27. 

## SÅ‚owa koÅ„cowe

W skrÃ³cie: **super wydarzenie**! Organizatorzy zrobili dobrÄ… robotÄ™ i zapewnili zadania o ciekawej tematyce. Wydarzenie byÅ‚o bardzo emocjonujÄ…ce, odbiegajÄ…c od typowej hackathonowej konwencji tworzenia demka aplikacji. Wierzymy, Å¼e serwery na nastÄ™pnej edycji byÅ‚yby dokÅ‚adniej przetestowane ;)

Finalnie zajÄ™liÅ›my 12 miejsce na 27 druÅ¼yn. Nie jest to spektakularny wynik, ale bardzo przewyÅ¼szyÅ‚ nasze oczekiwania - spodziewaliÅ›my siÄ™ ostatniego miejsca czy teÅ¼ DNF w niektÃ³rych taskach :) 

{{< img src="plakat.jpg" alt="Proroczy rysunek z pierwszych godzin" >}} 

## PodziÄ™kowania
 
PodziÄ™kowania dla druÅ¼yny Iteracyjne zapytanie DNS za miniony weekend:

- [Maciej Mazur](https://www.linkedin.com/in/maciej-mazur-90064b2b4/)
- [Benedykt Huszcza](https://www.linkedin.com/in/benedykt-huszcza-478b69289/)
- [Szymon Pasieczny](https://www.linkedin.com/in/szymon-pasieczny-4a664b215/)
- [Jakub Binkowski](https://www.linkedin.com/in/jakub-binkowski-80136825b/)

TakÅ¼e chciaÅ‚bym podziÄ™kowaÄ‡:
- Biniowi za przygotowanie akapitu o Sybil attack;
- Asi Cichej jako przewodniczÄ…cej GHOSTa za inicjatywÄ™ i pomoc z kwestiami organizacyjnymi wyjazdu; 
- caÅ‚ej ekipie organizatorÃ³w za zorganizowanie hackathonu; 
- Tobie, Å¼e przeczytaÅ‚Ã¦Å› ten artykuÅ‚!



